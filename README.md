# LMS_Reto3_Pipeline_De_Datos_End-to-End
En este proyecto se utiliza Kafka, Docker, Postgres, Conduktor, Zookeeper para realizar un pipeline que toma datos de transacciones a partir de un archivo csv procesarlo, cargarlos a un topico de kafka y que un consumidor tome esos datos y los persista en postgres.
